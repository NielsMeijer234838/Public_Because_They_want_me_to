Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to runs/et8g3527/runs/et8g3527_0
[2K---------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,949/5,000,000 [0m [ [33m0:00:01[0m < [36m1:06:03[0m , [31m1,261 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -122     |
| time/              |          |
|    fps             | 1224     |
|    iterations      | 1        |
|    time_elapsed    | 1        |
|    total_timesteps | 2048     |
---------------------------------
[2K------------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m4,014/5,000,000 [0m [ [33m0:00:04[0m < [36m1:38:35[0m , [31m845 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -195         |
| time/                   |              |
|    fps                  | 852          |
|    iterations           | 2            |
|    time_elapsed         | 4            |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0044055567 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.2          |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.0151      |
|    learning_rate        | 0.0003       |
|    loss                 | 0.192        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00377     |
|    std                  | 0.997        |
|    value_loss           | 1.05         |
------------------------------------------
[2K------------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m6,029/5,000,000 [0m [ [33m0:00:08[0m < [36m1:51:57[0m , [31m744 it/s[0m ]
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -201         |
| time/                   |              |
|    fps                  | 752          |
|    iterations           | 3            |
|    time_elapsed         | 8            |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0040851813 |
|    clip_fraction        | 0.0111       |
|    clip_range           | 0.2          |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.215       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.373        |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00112     |
|    std                  | 0.999        |
|    value_loss           | 2.71         |
------------------------------------------
[2K-----------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m8,172/5,000,000 [0m [ [33m0:00:11[0m < [36m1:54:12[0m , [31m729 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -217        |
| time/                   |             |
|    fps                  | 731         |
|    iterations           | 4           |
|    time_elapsed         | 11          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.006359378 |
|    clip_fraction        | 0.038       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.00392    |
|    std                  | 0.993       |
|    value_loss           | 0.797       |
-----------------------------------------
[2K-----------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m10,107/5,000,000 [0m [ [33m0:00:13[0m < [36m1:55:17[0m , [31m721 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -213        |
| time/                   |             |
|    fps                  | 727         |
|    iterations           | 5           |
|    time_elapsed         | 14          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.006708826 |
|    clip_fraction        | 0.0354      |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.23       |
|    explained_variance   | -0.0287     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.228       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.993       |
|    value_loss           | 1.8         |
-----------------------------------------
[2K-----------------------------------------â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -202        |
| time/                   |             |
|    fps                  | 721         |
|    iterations           | 6           |
|    time_elapsed         | 17          |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.006026997 |
|    clip_fraction        | 0.0339      |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.23       |
|    explained_variance   | -1.94       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0707      |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00354    |
|    std                  | 0.991       |
|    value_loss           | 0.783       |
-----------------------------------------
[2KTraceback (most recent call last):â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
[2K  File "/home/ketamine/Documents/Buas/Year2/Training_remote/Public_Because_They_want_me_to/training.py", line 51, in <module>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    model.learn(total_timesteps=5000000, callback=wandb_callback, progress_bar=True, reset_num_timesteps=False,tb_log_name=f"runs/{run.id}")
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learnâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    return super().learn(
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 336, in learnâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    self.train()
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 278, in trainâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    self.policy.optimizer.step()
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapperâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    out = func(*args, **kwargs)
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_gradâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    ret = func(self, *args, **kwargs)
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/torch/optim/adam.py", line 168, in stepâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    adam(
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/torch/optim/adam.py", line 318, in adamâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    func(params,
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/torch/optim/adam.py", line 441, in _single_tensor_adamâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
[2KKeyboardInterrupt;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
[35m   0%[0m [38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m12,149/5,000,000 [0m [ [33m0:00:17[0m < [36m1:56:10[0m , [31m716 it/s[0m ]
