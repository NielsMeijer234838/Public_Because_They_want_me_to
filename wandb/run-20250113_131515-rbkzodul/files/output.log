Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Logging to runs/rbkzodul/runs/rbkzodul_0
[2KTraceback (most recent call last):â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
[2K  File "/home/ketamine/Documents/Buas/Year2/Training_remote/Public_Because_They_want_me_to/training.py", line 48, in <module>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    model.learn(total_timesteps=5000000, callback=wandb_callback, progress_bar=True, reset_num_timesteps=False,tb_log_name=f"runs/{run.id}")
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learnâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    return super().learn(
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 323, in learnâ”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 218, in collect_rollouts1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    new_obs, rewards, dones, infos = env.step(clipped_actions)
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 206, in stepâ”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    return self.step_wait()
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 70, in step_wait [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    obs, self.reset_infos[env_idx] = self.envs[env_idx].reset()
[2K  File "/home/ketamine/.conda/envs/Test_pybullet/lib/python3.10/site-packages/stable_baselines3/common/monitor.py", line 83, in resetâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    return self.env.reset(**kwargs)
[2K  File "/home/ketamine/Documents/Buas/Year2/Training_remote/Public_Because_They_want_me_to/ot2_gym_wrapper.py", line 61, in resetâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    status = self.sim.reset(num_agents=1)
[2K  File "/home/ketamine/Documents/Buas/Year2/Training_remote/Public_Because_They_want_me_to/sim_class.py", line 199, in resetâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    self.create_robots(num_agents)
[2K  File "/home/ketamine/Documents/Buas/Year2/Training_remote/Public_Because_They_want_me_to/sim_class.py", line 90, in create_robotsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
    robotId = p.loadURDF("ot_2_simulation_v6.urdf", position, [0,0,0,1],
[2KKeyboardInterrupt;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
[35m   0%[0m [38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1,743/5,000,000 [0m [ [33m0:00:13[0m < [36m11:05:22[0m , [31m125 it/s[0m ]
